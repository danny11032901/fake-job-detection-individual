
#TF-IDF Analysis


import re
import string
import pandas as pd
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from bs4 import BeautifulSoup
from sklearn.feature_extraction.text import TfidfVectorizer

# Download NLTK resources

nltk.download('punkt')
nltk.download('punkt_tab')  
nltk.download('stopwords')


# Load dataset
df = pd.read_csv("fake_job_postings.csv")


#  TEXT CLEANING FUNCTION

def clean_text(text):
    text = str(text)
    text = BeautifulSoup(text, "html.parser").get_text()       
    text = re.sub(r'\d+', '', text)                            
    text = text.lower()                                       
    text = text.translate(str.maketrans('', '', string.punctuation))  
    words = word_tokenize(text)                                
    words = [w for w in words if w not in stopwords.words('english')]
    return ' '.join(words)


# APPLY CLEANING

df['clean_description'] = df['description'].apply(clean_text)


#  TF-IDF VECTORIZATION

vectorizer = TfidfVectorizer(
    max_features=1000,    
    ngram_range=(1, 2),  
    stop_words='english'  
)

tfidf_matrix = vectorizer.fit_transform(df['clean_description'].fillna(''))
feature_names = vectorizer.get_feature_names_out()

# Convert to DataFrame for better readability
tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)

print("\n TF-IDF Matrix Shape:", tfidf_df.shape)
print(tfidf_df.head())


#  TOP TERMS PER DOCUMENT

def get_top_keywords(tfidf_row, features, top_n=10):
    sorted_indices = tfidf_row.argsort()[::-1][:top_n]
    top_keywords = [(features[i], tfidf_row[i]) for i in sorted_indices]
    return top_keywords

# Example: Get top 10 keywords from first job description
example_index = 0
top_keywords = get_top_keywords(tfidf_matrix[example_index].toarray().flatten(), feature_names)
print("\nTop 10 Keywords for Job Posting 1:")
for word, score in top_keywords:
    print(f"{word}: {score:.4f}")


#  OPTIONAL: SHOW MOST FREQUENT TF-IDF TERMS OVERALL

import numpy as np

mean_tfidf = np.mean(tfidf_matrix.toarray(), axis=0)
top_indices = mean_tfidf.argsort()[::-1][:20]
print("\n Top 20 Keywords Across All Job Descriptions:")
for i in top_indices:
    print(f"{feature_names[i]}: {mean_tfidf[i]:.4f}")


#  (Optional) SAVE OUTPUT

tfidf_df.to_csv("TFIDF_Features.csv", index=False)
print("\nTF-IDF features saved to TFIDF_Features.csv ")
